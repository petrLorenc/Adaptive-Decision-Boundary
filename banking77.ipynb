{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf69258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import print_results, get_intents_selection, filter\n",
    "from custom_embeddings import create_embed_f\n",
    "from ADBThreshold import ADBThreshold\n",
    "from ood_train import evaluate\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import os, json, copy\n",
    "import tensorflow_hub as hub\n",
    "from statistics import mean\n",
    "\n",
    "time_pretraining = None\n",
    "accuracy_lst = []\n",
    "f1_lst = []\n",
    "time_train_lst = []\n",
    "time_inference_lst = []\n",
    "memory_lst = []\n",
    "time_pretraining_lst = []\n",
    "\n",
    "# 1 - LOAD DATASET\n",
    "# ------------------------------------------------------------\n",
    "dataset_name = 'banking77'\n",
    "dataset_path = os.path.join(\"datasets\", 'banking77.json')\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "with open(\"./datasets/banking77.json\") as f:\n",
    "    old_dataset = json.load(f)\n",
    "\n",
    "\n",
    "with open(\"results_3.txt\", \"w\") as f:\n",
    "    for KNOWN_RATIO, alpha in zip([0.25, 0.50, 0.75], [0.35, 0.4, 0.75]):\n",
    "        for test_idx in [1, 2, 3, 4, 5, 6, 7, 8, 9]:\n",
    "            \n",
    "            time_pretraining = None\n",
    "            accuracy_lst = []\n",
    "            f1_lst = []\n",
    "            time_train_lst = []\n",
    "            time_inference_lst = []\n",
    "            memory_lst = []\n",
    "            time_pretraining_lst = []\n",
    "            \n",
    "            for r in range(10):\n",
    "                model = ADBThreshold(alpha=alpha)\n",
    "                model_name = type(model).__name__\n",
    "                \n",
    "                if test_idx == 1 or test_idx == 4 or test_idx == 5 :\n",
    "                    embed_f = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "                    emb_name = 'use_dan'\n",
    "\n",
    "                if test_idx == 2 or test_idx == 6 or test_idx == 7:\n",
    "                    embed_f = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")\n",
    "                    emb_name = 'use_tran'\n",
    "\n",
    "                if test_idx == 3 or test_idx == 8 or test_idx == 9:\n",
    "                    embed_f = SentenceTransformer('stsb-roberta-base').encode\n",
    "                    emb_name = 'sbert'\n",
    "\n",
    "                dataset = copy.deepcopy(old_dataset)\n",
    "\n",
    "                num_classes = len(set([x[1] for x in dataset['train']]))\n",
    "                num_sel_classes = int(KNOWN_RATIO * num_classes)\n",
    "                selection = get_intents_selection(dataset['train'], num_intents=num_sel_classes)\n",
    "\n",
    "                filt_train = filter(dataset['train'], selection, 'train')\n",
    "                filt_test = filter(dataset['test'], selection, 'test')\n",
    "\n",
    "                dataset['train'] = filt_train\n",
    "                dataset['test'] = filt_test\n",
    "\n",
    "                # 4B-2 - CHOOSE EMBEDDING (with pre-training)\n",
    "                if test_idx == 4:\n",
    "                    embed_f, time_pretraining = create_embed_f(embed_f, dataset, limit_num_sents=None, type='cosface')\n",
    "                    emb_name = 'use_dan_cosface'\n",
    "\n",
    "                if test_idx == 5:\n",
    "                    embed_f, time_pretraining = create_embed_f(embed_f, dataset, limit_num_sents=None, type='triplet_loss')\n",
    "                    emb_name = 'use_dan_triplet_loss'\n",
    "\n",
    "                if test_idx == 6:\n",
    "                    embed_f, time_pretraining = create_embed_f(embed_f, dataset, limit_num_sents=None, type='cosface')\n",
    "                    emb_name = 'use_tran_cosface'\n",
    "\n",
    "                if test_idx == 7:\n",
    "                    embed_f, time_pretraining = create_embed_f(embed_f, dataset, limit_num_sents=None, type='triplet_loss')\n",
    "                    emb_name = 'use_tran_triplet_loss'\n",
    "\n",
    "                if test_idx == 8:\n",
    "                    embed_f, time_pretraining = create_embed_f(embed_f, dataset, limit_num_sents=None, type='cosface')\n",
    "                    emb_name = 'sbert_cosface'\n",
    "\n",
    "                if test_idx == 9:\n",
    "                    embed_f, time_pretraining = create_embed_f(embed_f, dataset, limit_num_sents=None, type='triplet_loss')\n",
    "                    emb_name = 'sbert_triplet_loss'\n",
    "\n",
    "                results_dct = evaluate(dataset, model, model_name, embed_f, limit_num_sents=None)\n",
    "\n",
    "                accuracy_lst.append(results_dct['accuracy'])\n",
    "                f1_lst.append(results_dct['f1'])\n",
    "                time_train_lst.append(results_dct['time_train'])\n",
    "                time_inference_lst.append(results_dct['time_inference'])\n",
    "                memory_lst.append(results_dct['memory'])\n",
    "\n",
    "                if time_pretraining is not None:\n",
    "                    time_pretraining_lst.append(time_pretraining)\n",
    "\n",
    "                print_results(dataset_name, model_name, emb_name, results_dct)\n",
    "\n",
    "            print(f\"{test_idx}\")\n",
    "            print(f'Dataset: {dataset_name}, known ratio: {KNOWN_RATIO}')\n",
    "            print(\n",
    "                f'accuracy: {round(mean(accuracy_lst), 1)},'\n",
    "                f' f1: {round(mean(f1_lst), 1)},'\n",
    "                f' time_train: {round(mean(time_train_lst), 1)},'\n",
    "                f' time_inference: {round(mean(time_inference_lst), 1)},'\n",
    "                f' memory: {round(mean(memory_lst), 1)},'\n",
    "                f' time_pretraining: {round(mean(time_pretraining_lst), 1) if len(time_pretraining_lst) != 0 else 0}')\n",
    "            \n",
    "            f.write(\n",
    "                f'Type={emb_name}; known_ratio={KNOWN_RATIO};'\n",
    "                f' test_idx={test_idx};'\n",
    "                f' accuracy={round(mean(accuracy_lst), 1)};'\n",
    "                f' f1={round(mean(f1_lst), 1)};'\n",
    "                f' time_train={round(mean(time_train_lst), 1)};'\n",
    "                f' time_inference={round(mean(time_inference_lst), 1)};'\n",
    "                f' memory={round(mean(memory_lst), 1)};'\n",
    "                f' time_pretraining={round(mean(time_pretraining_lst), 1) if len(time_pretraining_lst) != 0 else 0}')\n",
    "            f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b458e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d08786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}